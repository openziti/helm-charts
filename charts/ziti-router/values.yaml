
ctrl:
  # -- required control plane endpoint
  endpoint: # ctrl.example.com:6262

# -- Explicit proxy setting in the router configuration. Router can be deployed in a site 
# where all egress traffic is forwarded through an explicit proxy.
# The enrollment will also be forwarded through the proxy.
proxy: {}
#  type: http
#  address: 192.168.0.142
#  port: 3128

# -- common advertise-host for transport and edge listeners can also be
# specified separately via `edge.advertisedHost` and
# `linkListeners.transport.advertisedHost`
advertisedHost:

# Certificate signing request basic data
csr:
  # country: US
  # province: NC
  # locality: Charlotte
  # organization: NetFoundry
  # organizationalUnit: Ziti
  sans:
  # # you could specify additional SANS here - configurations from advertise hosts and
  # # service's will be collected automatically
  # -- additional DNS SANs
    dns: []
  #     - my.additional.host
  # -- additional IP SANs
    ip: []
  #     - "192.168.10.0"


# -- set name to value in containers' environment
env:
  # SOME_ENV: "true"
  

# listen for router links
linkListeners:
  transport:  # https://docs.openziti.io/docs/reference/configuration/router/#transport
    # -- cluster service target port on the container
    containerPort: 10080
    # -- DNS name that other routers will use to form mesh transport links with this router. Default is cluster-internal service DNS name:port.
    advertisedHost: #router11-transport.router-namespace.svc:443
    # -- cluster service, node port, load balancer, and ingress port
    advertisedPort: 443
    service:
      # -- create a cluster service for the router transport link listener
      enabled: true
      # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
      type: ClusterIP
      # -- service labels
      labels:
      # -- service annotations
      annotations:
    ingress:
      # -- create an ingress for the cluster service
      enabled: false
      # -- ingress annotations, e.g., to configure ingress-nginx
      annotations:

# listen for edge clients
edge:
  # -- enable the edge listener in the router config
  enabled: true
  # -- cluster service target port on the container
  containerPort: 3022
  # -- DNS name that edge clients will use to reach this router's edge listener
  advertisedHost: #router11-edge.ziti.example.com
  # -- cluster service, node port, load balancer, and ingress port
  advertisedPort: 443
  service:
    # -- create a cluster service for the edge listener
    enabled: true
    # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
    type: ClusterIP
    # -- service labels
    labels:
    # -- service annotations
    annotations:
  ingress:
    # -- create an ingress for the cluster service
    enabled: false
    # -- ingress annotations, e.g., to configure ingress-nginx
    annotations:

tunnel:
  # -- run mode for the router's built-in tunnel component: host, tproxy, proxy, or none
  mode: none
  # -- Ziti nameserver listener where OS must be configured to send DNS queries (default: udp://127.0.0.1:53)
  resolver:
  # -- CIDR range for the router's dynamic intercept IP addresses (default: 100.64.0.0/10)
  dnsSvcIpRange:
  # -- interface device name for setting up INPUT firewall rules if fw enabled.
  # It must be set but not needed in containers. Thus, it is set to lo by default
  lanIf: lo
  # -- the tproxy mode can be switched from iptables based interception to bpf interception by passing
  # the user space bpf program path. bpf kernel space program is expected to be loaded prior or during
  # router deployment, e.g. bpfman agent, hostpath, etc
  diverterPath:
  # -- list of Ziti services for which K8s services are to be created by this deployment, default is one cluster service port per Ziti service
  proxyServices: []
    #  # -- name of the Openziti service to forward data to
    #- zitiService: my_ziti_service
    #  # -- name suffix when not using the "default" proxy tunnel service, see above: "additionalK8sServices"
    #  k8sService: my_k8s_suffix
    #  # -- port the kubernetes service uses as listen port
    #  advertisedPort: 80
    #  # -- override the container port (default: advertisedPort)
    #  containerPort: 8443
  # -- if tunnel mode is "proxy", create the a cluster service named {{ release }}-proxy-default listening on each "advertisedPort" defined in "proxyServices"
  proxyDefaultK8sService:
    enabled: true
    type: ClusterIP
  # -- if tunnel mode is "proxy", create a separate cluster service for each Ziti service listed in "proxyServices" which k8sService == name
  proxyAdditionalK8sServices: []
    #- name: myservice
    #  type: ClusterIP

# -- read-only mountpoint for executables (must be in image's executable search PATH)
execMountDir:     /usr/local/bin
enrollJwtFile: enrollment.jwt
# -- enrollment one time token from the controller's management API
enrollmentJwt:
# -- read-only mountpoint for router identity secret specified in deployment for use by router run container
identityMountDir: /etc/ziti/identity
# -- writeable mountpoint where read-only config file is projected to allow router
# to write ./endpoints statefile in same dir
configMountDir:   /etc/ziti/config
# -- filename of router config YAML
configFile:       ziti-router.yaml

image:
  # -- container image tag for deployment
  repository: docker.io/openziti/ziti-router
  # -- container image tag (default is Chart's appVersion)
  tag:
  # -- deployment image pull policy
  pullPolicy: Always
  # pullSecrets:
  # command: ["sh", "-c", "while true; do sleep 86400; done"]
  # -- deployment container command
  command: ['/entrypoint.bash']
  # The templates inside this list are evaluated by the tpl function in the
  # deployment template because Helm values can not be directly referenced
  # inside the Values.yaml file (because it's just a data structure, not a
  # template).
  # -- deployment container command args and opts
  args: [ 'run', '{{ .Values.configMountDir }}/{{ .Values.configFile }}']

# deployment DNS policy
dnsPolicy: ClusterFirstWithHostNet

# -- it allows to override dns options when dnsPolicy is set to None.
dnsConfig: {}
#  nameservers: []
#  searches: []
#  options: []

# nameOverride: ""
# fullnameOverride: ""

# -- additional volumes to mount to ziti-router container
additionalVolumes: []
#  - name: additional-volume-1
#    volumeType: emptyDir
#    mountPath: /path/to/mount/1
#    secretName: name-of-secret
#  - name: additional-volume-2
#    volumeType: configMap
#    defaultMode: 0644
#    mountPath: /path/to/configmap/mount
#    configMapName: your-configmap-name
#  - name: additional-volume-3
#    volumeType: csi
#    driverName: csi.bpfd.dev
#    attributes: volumeAttributes
#    mountPath: /path/to/mount/3
#  - name: additional-volume-4
#    volumeType: emptyDir 
#    mountPath: /path/to/mount/4
#  - name: additional-volume-5
#    volumeType: hostPath 
#    behavior: DirectoryOrCreate
#    mountPath: /path/to/mount/4
#

# -- annotations to apply to all pods deployed by this chart
podAnnotations: {}

# -- deployment template spec security context
podSecurityContext:
  # -- this is the GID of "ziggy" run-as user in the container that has access
  # to any files created by the router process in the emptyDir volume used to
  # persist the endpoints state file
  fsGroup: 2171

# -- Host networking requested for a pod if set, i.e. tproxy ports enabled in the host namespace.
# i.e. egress gateway
hostNetwork: False

# -- deployment container security context
securityContext:
  # capabilities:
  #   add:
  #     - NET_ADMIN

# -- deployment container resources
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- deployment template spec node selector
nodeSelector: {}
#  kubernetes.io/role: master

# -- deployment template spec tolerations
tolerations: []
  # - key: node-role.kubernetes.io/master
  #   operator: Exists
  #   effect: NoSchedule

# -- deployment template spec affinity
affinity: {}

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  # -- required: place a storage claim for the ctrl endpoints state file
  enabled: true
  # -- annotations for the PVC
  annotations: {}
  # -- A manually managed Persistent Volume and Claim
  # Requires persistence.enabled: true
  # If defined, PVC must be created manually before volume will be bound
  existingClaim: ""
  ## minio data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # -- Storage class of PV to bind. By default it looks for the default storage class.
  # If the PV uses a different storage class, specify that here.
  storageClass: ""
  # -- PVC volume name
  volumeName:
  # -- PVC access mode: ReadWriteOnce (concurrent mounts not allowed), ReadWriteMany (concurrent allowed)
  accessMode: ReadWriteOnce
  # -- 50Mi is plenty for this state file 
  size: 50Mi
fabric:
  metrics:
    # -- configure fabric metrics in the router config
    enabled: false

forwarder:
  latencyProbeInterval: 10
  xgressDialQueueLength: 1000
  xgressDialWorkerCount: 128
  linkDialQueueLength: 1000
  linkDialWorkerCount: 32
  rateLimitedQueueLength: 5000
  rateLimitedWorkerCount: 64
