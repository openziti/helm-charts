
# nameOverride: ""
# fullnameOverride: ""

cluster:
  # -- the cluster mode (default: standalone; options: cluster-migrate, cluster-init, cluster-join); if joining a cluster, you must also set .edgeSignerPki.alternativeIssuer to the first node's edge-root issuer in same namespace
  mode: standalone
  # -- the trust domain part of the SPIFFE ID (required for cluster modes)
  trustDomain: ""
  # -- the node name part of the SPIFFE ID (required for cluster modes)
  nodeName: ""
  # -- required only when joining a cluster: reachable ctrl plane endpoint address of an existing node (example: ctrl1.ziti.example.com:443 or ziti-ctrl1-controller-ctrl:1280)
  endpoint: ""
  # -- TCP listen address and port for the controller CLI agent when running in clustered mode (do not expose)
  agentAppAddr: "tcp:127.0.0.1:10001"

clientApi:
  # -- cluster service target port on the container
  containerPort: 1280
  # -- global DNS name by which routers can resolve a reachable IP for this service
  advertisedHost: ""
  # -- cluster service, node port, load balancer, and ingress port
  advertisedPort: 443
  # -- besides advertisedHost, add these DNS SANs to the web identity and any ingresses
  dnsNames: []
  # -- besides advertisedHost and dnsNames, add these DNS SANs to any ingresses but not the web identity
  altDnsNames: []
  service:
    # -- create a cluster service for the client API - you probably want this unless you're crafting your own ClusterIP service out of band
    enabled: true
    # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
    type: LoadBalancer  # this is the only service that really needs to be exposed
  ingress:
    # -- create a TLS-passthrough ingress for the client API's ClusterIP service
    enabled: false
    # -- ingress class name
    ingressClassName: ""
    # -- ingress labels
    labels: {}
    # -- ingress annotations
    annotations: {}
    # -- deprecated: tls passthrough is required
    tls: {}
  traefikTcpRoute:
    # -- enable Traefik IngressRouteTCP
    enabled: false
    # -- IngressRouteTCP entrypoints
    entryPoints:
      - websecure
    # -- IngressRouteTCP labels
    labels: {}
  gatewayTlsRoute:
    # -- EXPERIMENTAL: enable Gateway API TLSRoute for this listener
    enabled: false
    # -- API version for TLSRoute (depends on installed Gateway API CRDs)
    apiVersion: gateway.networking.k8s.io/v1alpha2
    # -- TLSRoute labels
    labels: {}
    # -- parentRefs for TLSRoute, usually a Traefik-managed Gateway listener
    # parentRefs:
    #   - name: traefik-gateway
    #     namespace: traefik
    #     sectionName: websecure
    parentRefs: []

# -- by default, there's no need for a separate cluster service, ingress, or
# load balancer for the management API because it shares a TLS listener with the
# client API, and is reachable at the same address and presents the same web
# identity cert; you may configure a separate service, ingress, load balancer,
# etc.  for the management API by setting managementApi.service.enabled=true
managementApi:
  # -- cluster service target port on the container
  containerPort: 1281
  # -- global DNS name by which routers can resolve a reachable IP for this service
  advertisedHost: "{{ .Values.clientApi.advertisedHost }}"
  # -- cluster service, node port, load balancer, and ingress port
  advertisedPort: "{{ .Values.clientApi.advertisedPort }}"
  # -- besides advertisedHost, add these DNS SANs to the web identity and any mgmt api ingresses
  dnsNames: []
  # -- besides advertisedHost and dnsNames, add these DNS SANs to any mgmt api ingresses, but not the web identity
  altDnsNames: []
  service:
    # -- create a separate cluster service for the mgmt API enabled: true means provide this API on a separate port, otherwise share server port with clientApi
    enabled: false
    # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
    type: ClusterIP  # this doesn't need to be exposed if you exclusively manage with ZAC also running in the same cluster
  ingress:
    # -- create a TLS-passthrough ingress for the client API's ClusterIP service
    enabled: false
    # -- ingress class name
    ingressClassName: ""
    # -- ingress labels
    labels: {}
    # -- ingress annotations
    annotations: {}
    # -- deprecated: tls passthrough is required
    tls: {}
  traefikTcpRoute:
    # -- enable Traefik IngressRouteTCP
    enabled: false
    # -- IngressRouteTCP entrypoints
    entryPoints:
      - websecure
    # -- IngressRouteTCP labels
    labels: {}
  gatewayTlsRoute:
    # -- EXPERIMENTAL: enable Gateway API TLSRoute for this listener
    enabled: false
    # -- API version for TLSRoute (depends on installed Gateway API CRDs)
    apiVersion: gateway.networking.k8s.io/v1alpha2
    # -- TLSRoute labels
    labels: {}
    # -- parentRefs for TLSRoute, usually a Traefik-managed Gateway listener
    # parentRefs:
    #   - name: traefik-gateway
    #     namespace: traefik
    #     sectionName: websecure
    parentRefs: []

ctrlPlane:
  # -- cluster service target port on the container
  containerPort: "{{ .Values.clientApi.containerPort }}"
  # -- global DNS name by which routers can resolve a reachable IP for this
  # service: default is cluster service DNS name which assumes all routers are
  # inside the same cluster
  advertisedHost: "{{ .Values.clientApi.advertisedHost }}"
  # -- cluster service, node port, load balancer, and ingress port
  advertisedPort: "{{ .Values.clientApi.advertisedPort }}"
  # -- besides advertisedHost, add these DNS SANs to the ctrl plane identity and any ctrl plane ingresses
  dnsNames: []
  service:
    # -- create a separate cluster service for the ctrl plane (default: disabled, shares listener with clientApi via ALPN)
    enabled: false
    # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
    type: ClusterIP
  ingress:
    # -- create an ingress for the cluster service
    enabled: false
    # -- ingress class name
    ingressClassName: ""
    # -- ingress labels
    labels: {}
    # -- ingress annotations
    annotations: {}
    # -- deprecated: tls passthrough is required
    tls: {}
  # -- DEPRECATED: The ctrl-plane root CA is deprecated. The ctrl-plane identity is now
  # issued by edge-signer-issuer. This option is preserved for backward compatibility but
  # the ctrl-plane-root-cert and ctrl-plane-root-issuer resources are orphaned.
  # (example: "my-issuer" or `{name: "my-issuer", kind: "Issuer", group: "cert-manager.io"}`)
  alternativeIssuer: {}
  traefikTcpRoute:
    # -- enable Traefik IngressRouteTCP
    enabled: false
    # -- IngressRouteTCP entrypoints
    entryPoints:
      - websecure
    # -- IngressRouteTCP labels
    labels: {}
  gatewayTlsRoute:
    # -- EXPERIMENTAL: enable Gateway API TLSRoute for this listener
    enabled: false
    # -- API version for TLSRoute (depends on installed Gateway API CRDs)
    apiVersion: gateway.networking.k8s.io/v1alpha2
    # -- TLSRoute labels
    labels: {}
    # -- parentRefs for TLSRoute, usually a Traefik-managed Gateway listener
    # parentRefs:
    #   - name: traefik-gateway
    #     namespace: traefik
    #     sectionName: websecure
    parentRefs: []

console:
  # -- enable the Ziti Admin Console (ZAC) at URL path "/zac" on the same port as the management API (default: true)
  enabled: true
  # -- override the address printed in Helm release notes if you configured an alternative DNS SAN for the console, i.e.
  # `{"host": "console.ziti.example.com", "port": 443}`
  altIngress: {}
    # host: ""
    # port: 443

# -- set name to value in containers' environment
env: {}
# SOME_ENV: "true"

# -- set secrets as environment variables in the container
envSecrets: {}
#  - name: SOME_SECRET_ENV
#    valueFrom:
#      secretKeyRef:
#        name: some-secret
#        key: some_secret_key


# -- allow for using a custom admin secret, which has to be created beforehand
# if enabled, the admin secret will not be generated by this Helm chart
useCustomAdminSecret: false

# -- set the admin user and password from a custom secret
# The custom admin secret must be of the following format:
# apiVersion: v1
# kind: Secret
# metadata:
#   name: myCustomAdminSecret
# type: Opaque
# data:
#   admin-user:
#   admin-password:
customAdminSecretName: ""

prometheus:
  # -- cluster service target port on the container
  containerPort: 9090
  # -- cluster service, node port, load balancer, and ingress port
  advertisedPort: 443
  # -- DNS name to advertise in place of the default internal cluster name built from the Helm release name
  advertisedHost: ""
  service:
    # -- create a cluster service for the deployment
    enabled: false
    # -- expose the service as a ClusterIP, NodePort, or LoadBalancer
    type: ClusterIP
    # -- extra labels for matching only this service, ie. serviceMonitor
    labels:
      app: prometheus
    annotations: {}
  # -- minimum TLS version to offer to clients
  minTLSVersion: TLS1.2
  # -- maximum TLS version to offer to clients
  maxTLSVersion: TLS1.3


  # ServiceMonitor configuration
  serviceMonitor:
    # -- If enabled, and prometheus service is enabled, ServiceMonitor resources for Prometheus Operator are created
    enabled: true
    # -- Alternative namespace for ServiceMonitor resources
    namespace: null
    # -- Namespace selector for ServiceMonitor resources
    namespaceSelector: {}
    # -- ServiceMonitor annotations
    annotations: {}
    # -- Additional ServiceMonitor labels
    labels: {}
    # -- ServiceMonitor scrape interval
    interval: null
    # -- ServiceMonitor scrape timeout in Go duration format (e.g. 15s)
    scrapeTimeout: null
    # -- ServiceMonitor relabel configs to apply to samples before scraping
    # (defines `relabel_configs`;  [reference](https://prometheus.io/docs/prometheus/latest/configuration/configuration))
    relabelings: []
    # -- ServiceMonitor relabel configs to apply to samples as the last step before ingestion ([reference](https://prometheus.io/docs/prometheus/latest/configuration/configuration))
    metricRelabelings: []
    # -- ServiceMonitor will add labels from the service to the Prometheus metric ([reference](https://prometheus.io/docs/prometheus/latest/configuration/configuration))
    targetLabels: []
    # -- ServiceMonitor will use http by default, but you can pick https as well
    scheme: https
    # -- ServiceMonitor will use these tlsConfig settings to make the health check requests
    tlsConfig:
      # -- set TLS skip verify, because the SAN will not match with the pod IP
      insecureSkipVerify: true

ca:
  # Note: The renewBefore and duration fields must be specified using a Go
  # time.Duration string format, which does not allow the d (days) suffix.
  # You must specify these values using s, m, and h suffixes instead.
  # duration: 2160h # 90d
  # renewBefore: 360h # 15d
  # -- Go time.Duration string format
  duration: 87840h # 3660d / 10y
  # -- Go time.Duration string format
  renewBefore: 720h # 30d
  # -- Set a custom cluster domain if other than cluster.local
  clusterDomain: "cluster.local"

cert:
  # Note: The renewBefore and duration fields must be specified using a Go
  # time.Duration string format, which does not allow the d (days) suffix.
  # You must specify these values using s, m, and h suffixes instead.
  # TODO lower this value!
  # duration: 2160h   # 90d
  # renewBefore: 360h # 15d
  # -- server certificate duration as Go time.Duration string format
  duration: 87840h    # 3660d / 10 y
  # -- rewnew server certificates before expiry as Go time.Duration string format
  renewBefore: 720h   # 30d

# The edge signer PKI is now the SINGLE root of trust for the entire Ziti network.
# All ctrl-plane and web-binding certificates are now issued from the edge-signer-issuer.
edgeSignerPki:
  # -- deprecated - this can not be disabled - generate the PKI root of trust for the Ziti network (edge-root CA) and issue the edge-signer intermediate
  enabled: true
  # -- obtain the edge signer intermediate CA from an existing issuer instead of generating a new PKI - used when joining a cluster
  alternativeIssuer: {}
  # -- type of alternative issuer: Issuer, ClusterIssuer
  # kind:
  # -- metadata name of the alternative issuer
  # name:
  admin_client_cert:
    # -- create a client certificate for the admin user
    enabled: false
    # -- admin client certificate duration as Go time.Duration
    duration: 8760h
    # -- renew admin client certificate before expiry as Go time.Duration
    renewBefore: 720h

# DEPRECATION NOTICE: The separate web-binding root CA is deprecated.
# Web certificates are now issued from the edge-signer-issuer (unified PKI).
# The webBindingPki.alternativeIssuer option is preserved for backward compatibility
# but the web-root-cert and web-root-issuer resources are orphaned.
webBindingPki:
  # -- enable web binding PKI (certificates issued from edge-signer-issuer) enabled by default for reverse compatibility
  # because each web binding gets its own leaf cert with specific SANs, and when disabled the generic ctrl plane
  # identity cert is used for all web bindings, which is fine in most cases
  enabled: true
  altServerCerts: []
    #  # -- request an alternative server certificate from a cert-manager issuer
    #  mode: certManager
    #  # -- name of the tls secret for cert-manager to create and manage the server
    #  #    certificate and private key
    #  # -- request a certificate for these alternative names distinct from advertisedHost and dnsNames of the clientApi, managementApi, and ctrlPlane
    #  altDnsNames: []
    #  secretName: ziti-controller-alt-server-cert
    #  # -- issuer ref to use when requesting the alternative server certificate
    #  issuerRef:
    #    group: cert-manager.io
    #    kind: ClusterIssuer
    #    name: cloudflare-dns01-issuer
    #  # -- where to mount the tls secret on the pod - must not collide with another mountpoint
    #  mountPath: /etc/ziti/alt-server-cert

    #  # -- use an alternative certificate and key from a tls secret declared in additionalVolumes
    #- mode: secret
    #  # -- name of the tls secret from additionalVolumes with the alternative
    #  #    server certificate and private key
    #  secretName: ziti-controller-alt-server-cert

    #  # -- use an explicit file path to the alternative server certificate and key
    #- mode: localFile
    #  # -- 'localFile': path to the alternative server certificate
    #  serverCert:
    #  # -- 'localFile': path to the alternative server key
    #  serverKey:
  # -- obtain the web identity from an existing issuer instead of generating a new PKI
  alternativeIssuer: {}
  # -- type of alternative issuer: Issuer, ClusterIssuer
  # kind:
  # -- metadata name of the alternative issuer
  # name:
  # -- minimum TLS version to offer to clients
  minTLSVersion: TLS1.2
  # -- maximum TLS version to offer to clients
  maxTLSVersion: TLS1.3

spireAgent:
  # -- if you are running a container with the spire-agent binary installed
  # then this will allow you to add the hostpath necessary for connecting to
  # the spire socket
  enabled: false
  # -- file path of the spire socket mount
  spireSocketMnt: /run/spire/sockets

image:
  # -- homeDir for admin login shell must align with container image's ~/.bashrc for ziti CLI auto-complete to work
  homeDir: /home/ziggy
  # -- container image repository for app deployment
  repository: docker.io/openziti/ziti-controller
  # -- override the container image tag specified in the chart
  tag: ""
  # -- deployment image pull policy
  pullPolicy: IfNotPresent
  # -- container entrypoint command
  command: ["ziti", "controller", "run"]
  # -- args for the entrypoint command
  args: ["{{ include \"configMountDir\" . }}/ziti-controller.yaml"]
  # -- additional arguments can be passed directly to the container to modify ziti runtime arguments
  additionalArgs: []

# -- name of the BoltDB file
dbFile:         ctrl.db

ctrlPlaneCasBundle:
  # -- namespaces where trust-manager will create the Bundle resource containing
  # Ziti's trusted CA certs (default: empty means all namespaces)
  namespaceSelector: {}
    # matchLabels:
    #   openziti.io/namespace: "enabled"
    # matchLabels:
    #   kubernetes.io/metadata.name: ziti
  # -- name of the ConfigMap managed by the trust-manager Bundle resource. For cluster-join nodes, set this to the first
  # node's ConfigMap name (e.g., "ziti-ctrl1-controller-ctrl-plane-cas") so all nodes share the same trust bundle. For
  # solo nodes, leave empty to use the default name based on this release. If subsequent nodes are added without this
  # value, a harmless, redundant Bundle and ConfigMap resource will be created.
  configMapName: ""

# -- additional volumes to mount to ziti-controller container
additionalVolumes: []
#  - name: additional-volume-1
#    volumeType: secret
#    mountPath: /path/to/mount/1
#    secretName: name-of-secret
#  - name: additional-volume-2
#    volumeType: configMap
#    mountPath: /path/to/configmap/mount
#    configMapName: your-configmap-name
#  - name: additional-volume-3
#    volumeType: emptyDir
#    mountPath: /path/to/mount/2

# -- annotations to apply to all pods deployed by this chart
podAnnotations: {}

# -- deployment template spec security context
podSecurityContext:
  # -- the GID of the group that should own any files created by the container, especially the BoltDB file
  fsGroup: 2171

# -- deployment container security context
securityContext: {}
  # capabilities:
  #   add:
  #     - NET_ADMIN

# -- deployment container resources
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- deployment template spec node selector
nodeSelector: {}
#  kubernetes.io/role: master

# -- deployment template spec tolerations
tolerations: []
  # - key: node-role.kubernetes.io/master
  #   operator: Exists
  #   effect: NoSchedule

# -- deployment template spec affinity
affinity: {}

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  # -- required: place a storage claim for the BoltDB persistent volume
  enabled: true
  # -- annotations for the PVC
  annotations: {}

  # -- A manually managed Persistent Volume and Claim Requires
  # persistence.enabled=true. If defined, PVC must be created manually before
  # volume will be bound.
  existingClaim: ""

  ## minio data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # -- Storage class of PV to bind. By default it looks for the default storage class.
  # If the PV uses a different storage class, specify that here.
  storageClass: ""
  # -- PVC volume name
  VolumeName: ""
  # -- PVC access mode: ReadWriteOnce (concurrent mounts not allowed), ReadWriteMany (concurrent allowed)
  accessMode: ReadWriteOnce
  # -- 2GiB is enough for tens of thousands of entities, but feel free to make it larger
  size: 2Gi

## DEPRECATED - This will be going away in a future release
## Use additionalConfigs block for event configuration
fabric:
  events:
    # -- enable fabric event logger and file handler
    enabled: false
    network:
      # -- matching interval age and reporting interval ensures coherent metrics from fabric events
      intervalAgeThreshold: 5s
      # -- matching interval age and reporting interval ensures coherent metrics from fabric events
      metricsReportInterval: 5s
    mountDir: /var/run/ziti
    fileName: fabric-events.json
    subscriptions:
      - type: fabric.circuits
      - type: fabric.links
      - type: fabric.routers
      - type: fabric.terminators
      - type: metrics
        sourceFilter: .*
        metricFilter: .*
      - type: edge.sessions
      - type: edge.apiSessions
      - type: fabric.usage  # used by zrok for limits enforcement
        version: 3
      - type: services
      - type: edge.entityCounts
        interval: 5s

network:
  # -- routeTimeoutSeconds controls the number of seconds the controller will wait for a route attempt to succeed.
  routeTimeoutSeconds:  10

  # -- createCircuitRetries controls the number of retries that will be attempted to create a path (and terminate it)
  # for new circuits.
  createCircuitRetries: 2

  # -- pendingLinkTimeoutSeconds controls how long we'll wait before creating a new link between routers where
  # there isn't an established link, but a link request has been sent
  pendingLinkTimeoutSeconds: 10

  # -- Defines the period that the controller re-evaluates the performance of all of the circuits
  # running on the network.
  cycleSeconds: 15

  # -- Sets router minimum cost. Defaults to 10
  minRouterCost: 10

  # -- Sets how often a new control channel connection can take over for a router with an existing control channel connection
  # Defaults to 1 minute
  routerConnectChurnLimit: 1m

  # -- Sets the latency of link when it's first created. Will be overwritten as soon as latency from the link is actually
  # reported from the routers. Defaults to 65 seconds.
  initialLinkLatency: 65s

  smart:
    # -- Defines the fractional upper limit of underperforming circuits that are candidates to be re-routed. If
    # smart routing detects 100 circuits that are underperforming, and `smart.rerouteFraction` is set to `0.02`,
    # then the upper limit of circuits that will be re-routed in this `cycleSeconds` period will be limited to
    # 2 (2% of 100).
    rerouteFraction: 0.02

    # -- Defines the hard upper limit of underperforming circuits that are candidates to be re-routed. If smart
    # routing detects 100 circuits that are underperforming, and `smart.rerouteCap` is set to `1`, and
    # `smart.rerouteFraction` is set to `0.02`, then the upper limit of circuits that will be re-routed in this
    # `cycleSeconds` period will be limited to 1.
    rerouteCap: 4

# -- Append additional config blocks in specific top-level keys: edge,
# web, network, ctrl. If events are defined here, they replace the default
# events section entirely.
additionalConfigs:
  ctrl: {}
  network: {}
  healthChecks: {}
  web: {}
  events: {}
  #    ampqLogger:
  #      subscriptions:
  #        - type: fabric.usage
  #          version: 3
  #      handler:
  #        type: amqp
  #        format: json
  #        url: "amqps://USER:PASSWORD@HOST:5671"
  #        queue: events
  #        # buffer size is how many events can be shipped per interval, larger networks need a larger buffer
  #        bufferSize: 1000
  #    jsonLogger:
  #      subscriptions:
  #        - type: metrics
  #          sourceFilter: .*
  #          metricFilter: .*
  #      handler:
  #        type: file
  #        format: json
  #        path: /var/run/ziti/metrics.log
  #        maxsizemb: 1024
  #        maxbackups: 3
